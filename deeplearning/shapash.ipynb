{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchVelocityModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PitchVelocityModel, self).__init__()\n",
    "        # Fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(num_features, 1024)\n",
    "        self.fc2 = torch.nn.Linear(1024, 512)\n",
    "        self.fc3 = torch.nn.Linear(512, 256)\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.fc5 = torch.nn.Linear(128, 64)\n",
    "        self.fc6 = torch.nn.Linear(64, 32)\n",
    "        self.fc7 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "        # Relu activation function\n",
    "        self.relu = torch.nn.ReLU()  \n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    batches = [data[i:i + batch_size] for i in range(0, data.size(0), batch_size)]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaled datasets\n",
    "X_train_scaled = pd.read_csv('X_train_scaled.csv').values\n",
    "X_val_scaled = pd.read_csv('X_val_scaled.csv').values\n",
    "X_test_scaled = pd.read_csv('X_test_scaled.csv').values\n",
    "\n",
    "# Convert the NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Load the labels\n",
    "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
    "y_val = pd.read_csv('y_val.csv').values.ravel()\n",
    "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Load your trained model\n",
    "model = PitchVelocityModel(X_train_scaled.shape[1])\n",
    "model.load_state_dict(torch.load('pitch_velocity_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# If using GPU, move tensors to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Use DeepExplainer for each batch and aggregate the results\u001b[39;00m\n\u001b[0;32m      8\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model, X_train_tensor)\n\u001b[1;32m----> 9\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_test_batches\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/adam.bloebaum/Documents/GitHub/biomech/deeplearning/scaler.pk1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m preprocessing \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m: scaler}\n",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Use DeepExplainer for each batch and aggregate the results\u001b[39;00m\n\u001b[0;32m      8\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model, X_train_tensor)\n\u001b[1;32m----> 9\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m [\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m X_test_batches]\n\u001b[0;32m     11\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/adam.bloebaum/Documents/GitHub/biomech/deeplearning/scaler.pk1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m preprocessing \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m: scaler}\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:125\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m        were chosen as \"top\".\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:191\u001b[0m, in \u001b[0;36mPyTorchDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# run attribution computation graph\u001b[39;00m\n\u001b[0;32m    190\u001b[0m feature_ind \u001b[38;5;241m=\u001b[39m model_output_ranks[j, i]\n\u001b[1;32m--> 191\u001b[0m sample_phis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterim:\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:125\u001b[0m, in \u001b[0;36mPyTorchDeep.gradient\u001b[1;34m(self, idx, inputs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[1;32m--> 125\u001b[0m         grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m             grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\torch\\autograd\\__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    391\u001b[0m         grad_outputs_\n\u001b[0;32m    392\u001b[0m     )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    405\u001b[0m         output\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[0;32m    409\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\torch\\utils\\hooks.py:136\u001b[0m, in \u001b[0;36mBackwardHook._set_user_hook.<locals>.hook\u001b[1;34m(grad_input, _)\u001b[0m\n\u001b[0;32m    133\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pack_with_none(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_tensors_index, grad_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_inputs)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_hooks:\n\u001b[1;32m--> 136\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:240\u001b[0m, in \u001b[0;36mdeeplift_grad\u001b[1;34m(module, grad_input, grad_output)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_type \u001b[38;5;129;01min\u001b[39;00m op_handler:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op_handler[module_type]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear_1d\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop_handler\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munrecognized nn.Module: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adam.bloebaum\\AppData\\Local\\miniconda3\\envs\\driveline\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:347\u001b[0m, in \u001b[0;36mnonlinear_1d\u001b[1;34m(module, grad_input, grad_output)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# handles numerical instabilities where delta_in is very small by\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# just taking the gradient in those cases\u001b[39;00m\n\u001b[0;32m    345\u001b[0m grads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m grad_input]\n\u001b[0;32m    346\u001b[0m grads[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39mabs(delta_in\u001b[38;5;241m.\u001b[39mrepeat(dup0)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-6\u001b[39m, grad_input[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m--> 347\u001b[0m                        \u001b[43mgrad_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta_in\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdup0\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(grads)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Define the batch size\n",
    "batch_size = 32  # Adjust as necessary\n",
    "\n",
    "# Create batches from your test tensor\n",
    "X_test_batches = batchify(X_test_tensor, batch_size)\n",
    "\n",
    "# Use DeepExplainer for each batch and aggregate the results\n",
    "explainer = shap.DeepExplainer(model, X_train_tensor)\n",
    "shap_values = [explainer.shap_values(batch) for batch in X_test_batches]\n",
    "\n",
    "scaler = joblib.load('C:/Users/adam.bloebaum/Documents/GitHub/biomech/deeplearning/scaler.pk1')\n",
    "preprocessing = {'scaler': scaler}\n",
    "\n",
    "# Use Shapash\n",
    "xpl = SmartExplainer()\n",
    "\n",
    "# Generate model predictions for Shapash\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    y_pred_shapash = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "xpl.compile(x=X_test_scaled, model=model, preprocessing=preprocessing, y_pred=y_pred_shapash)\n",
    "xpl.to_pandas().head()\n",
    "\n",
    "# Summary plot\n",
    "xpl.plot.features_importance()\n",
    "plt.savefig('C:/Users/adam.bloebaum/Documents/GitHub/biomech/deeplearning/outputs') # Save the plot as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpl.run_app(title_story='Model Explanations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driveline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
